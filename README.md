Data_scientist_projects




Voici les projets sur lequels j'ai travaillé pendant mon master.
Here are the project I worked on during my master.

Chaque projet a été présenté lors d'un examen.
Each project lead to an exam.

Chaque dossier contient:
- 1 ou plusieurs Notebook pour le prétraitement/nettoyage des données
- 1 ou plusieurs Notebook pour la recherche et l'entrainement de modèle
- 1 présentation (en Français) ayant servi de support durant l'examen.

Each folder contains:
- 1 or more notebooks for data preprocessing/cleaning
- 1 or more notebooks for model research and training
- 1 presentation (in French) used as support during the exam.

## 1. Analyse de donnees de systemes educatifs / Educational system data analysis

#### Mission:
Analyse exploratoire dans le cadre d'une expansion à l'international d'une start-up proposant des cours en ligne.
#### Source des données:
Banque mondiale
https://datacatalog.worldbank.org/dataset/education-statistics
#### Compétence évaluées:
Mettre en place un environnement python.
Effectuer des représentations graphiques avec une librairie python.

#### Assignment:
Exploratory analysis as part of an international expansion of a start-up offering online courses.
#### Data source:
World bank
https://datacatalog.worldbank.org/dataset/education-statistics
#### Skills assessed:
Set up a Python environment.
Make graphical representations with a python library.


## 2. Application de sante publique / Public health apps

#### Mission:
Proposer une idée d'application pour l'agence de santé publique en rapport avec l'alimentation.
#### Source des données:
Open Food Facts
https://world.openfoodfacts.org/
#### Compétence évaluées:
Analyses statistiques univariées / multivariée.
Opérations de nettoyage pertinentes.

#### Assignment:
Propose an application idea for the public health agency related to food.
#### Data source:
Open Food Facts
https://world.openfoodfacts.org/
#### Skills assessed:
Univariate / multivariate statistical analyses.
Relevant cleaning operations.


## 3. Anticipation des besoins en consommation electrique / Anticipation of electricity consumption needs
 
#### Mission:
Tenter de prédire les émissions en CO2 et la consommation totale d'énergie des bâtiments publics de la ville de Seattle en 2050.
#### Source de données:
Ville de Seattle
https://data.seattle.gov/dataset/2016-Building-Energy-Benchmarking/2bpz-gwpy
#### Compétences évaluées:
Mise en place d'un modèle d'apprentissage supervisé.
Recherche d'hyperparamètres pour algorithme supervisé.
Évaluation du modèle supervisé.

#### Assignment:
Attempt to predict the CO2 emissions and total energy consumption of public buildings in the city of Seattle in 2050.
#### Data source:
City of Seattle
https://data.seattle.gov/dataset/2016-Building-Energy-Benchmarking/2bpz-gwpy
#### Skills assessed:
Implementation of a supervised learning model.
Search for hyperparameters for supervised algorithm.
Supervised model evaluation.

## 4. Segmentation clientèle / Customer segmentation - unsupervised learning

#### Mission:
Segmentation clientèle pour l'entreprise Olist (e-commerce, Brésil) à destination du service marketing.
#### Source de données:
Public dataset by Olist
https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce
#### Compétences évaluées:
Mise en place d'un modèle d'apprentissage non-supervisé.
Recherche d'hyperparamètres pour algorithme non-supervisé.
Évauation d'un modèle non-supervisé.

#### Assignment:
Customer segmentation for the company Olist (e-commerce, Brazil) for the marketing department.
#### Data source:
Public dataset by Olist
https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce
#### Skills assessed:
Implementation of an unsupervised learning model.
Search hyperparameters for unsupervised algorithm.
Unsupervised model evaluation.


## 5. Classification automatique de biens de consommation /  Automatic classification of consumer goods - Image and text recognition

#### Mission:
Création d'un moteur de classification automatique des articles d'un site de e-commerce.
#### Source des données:
Openclassrooms
https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Projet+-+Textimage+DAS+V2/Dataset+projet+pre%CC%81traitement+textes+images.zip
#### Compétences évaluées:
Représentation graphique de données à grande dimensions.
Mise en oeuvre de techniques de réduction de dimensions.
Prétraitement de données textes.
Prétraitement de données images.
Mise en place d'un model de réseau de neurones.

#### Assignment:
Creation of an automatic classification engine for articles on an e-commerce site.
#### Data source::
Openclassrooms
https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Project+-+Textimage+DAS+V2/Dataset+project+pre%CC%81processing +texts+images.zip
#### Skills assessed:
Graphical representation of large-scale data.
Implementation of dimension reduction techniques.
Text data preprocessing.
Image data preprocessing.
Implementation of a neural network model.


## 6. Implémentation d'un modèle de scoring / Implementing a scoring model

#### Mission:
Mise en oeuvre d'un outil de "scoring crédit" pour attribution de crédit à la consommation.
Implémentation d'un dashboard interactif pour expliquer la décision du modèle.
#### Source des données:
Home Credit Default Risk
https://www.kaggle.com/c/home-credit-default-risk/data
#### Compétences évaluées:
Déployer un modèle via une API sur le web.
Utiliser un logiciel de version de code pour assurer l'intégration du modèle.
Réaliser un dashboard interactif.

#### Assignment:
Implementation of a "credit scoring" tool for granting consumer credit.
Implementation of an interactive dashboard to explain the decision of the model.
#### Data source:
Home Credit Default Risk
https://www.kaggle.com/c/home-credit-default-risk/data
#### Skills assessed:
Deploy a model via an API on the web.
Use code release software to ensure model integration.
Create an interactive dashboard.


## 7. Déployer un modèle dans le cloud / Deploy a model in the cloud

#### Mission:
Faire le prétraitement de données et la réduction de dimension dans un environnement Big-Data en utilisant Pyspark et AWS.
#### Source de données:
Fruits 360
https://www.kaggle.com/datasets/moltean/fruits
#### Compétences évaluées:
Manipuler des données dans un environnement Big Data.
Paralléliser des opérations de calcul avec Pyspark.

#### Assignment:
Perform data pre-processing and dimension reduction in a Big-Data environment using Pyspark and AWS.
#### Data source:
Fruit 360
https://www.kaggle.com/datasets/moltean/fruit
#### Skills assessed:
Manipulate data in a Big Data environment.
Parallelize calculation operations with Pyspark.
